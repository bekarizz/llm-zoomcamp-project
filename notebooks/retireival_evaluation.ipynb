{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b13e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/workspaces/llm-zoomcamp-project/')\n",
    "\n",
    "from cards import make_table_cards, make_column_cards, make_example_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c627540",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_cards = make_example_cards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a2ba756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 19 cards into industrial_sql_rag with sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2613/3798259675.py:20: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(COLL, vectors_config=VectorParams(size=len(vecs[0]), distance=Distance.COSINE))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "from sqlalchemy import create_engine, text\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "DB_URL = os.getenv(\"DB_URL\", \"postgresql+psycopg2://rag:ragpass@localhost:5432/ragdb\")\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\", \"http://localhost:6333\")\n",
    "COLL = os.getenv(\"QDRANT_COLLECTION\", \"industrial_sql_rag\")\n",
    "EMB = os.getenv(\"EMBED_MODEL\", \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "docs = make_example_cards()\n",
    "model = SentenceTransformer(EMB)\n",
    "vecs = model.encode([d[\"text\"] for d in docs], normalize_embeddings=True)\n",
    "\n",
    "client = QdrantClient(QDRANT_URL)\n",
    "if COLL in [c.name for c in client.get_collections().collections]:\n",
    "    client.delete_collection(COLL)\n",
    "client.recreate_collection(COLL, vectors_config=VectorParams(size=len(vecs[0]), distance=Distance.COSINE))\n",
    "\n",
    "points = [PointStruct(id=i, vector=vecs[i].tolist(), payload=docs[i]) for i in range(len(docs))]\n",
    "client.upsert(COLL, points=points)\n",
    "print(f\"Indexed {len(points)} cards into {COLL} with {EMB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "694f1ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "from typing import List, Dict\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "BM25_PATH = os.getenv(\"BM25_PATH\", \"data/bm25.pkl\")\n",
    "\n",
    "def build_bm25(docs: List[Dict]):\n",
    "    corpus = [d[\"text\"].lower().split() for d in docs]\n",
    "    return BM25Okapi(corpus)\n",
    "\n",
    "def save_bm25(bm25, docs):\n",
    "    with open(BM25_PATH, \"wb\") as f:\n",
    "        pickle.dump({\"bm25\": bm25, \"docs\": docs}, f)\n",
    "\n",
    "def load_bm25():\n",
    "    with open(BM25_PATH, \"rb\") as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj[\"bm25\"], obj[\"docs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9de1a52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 index built over 19 docs\n"
     ]
    }
   ],
   "source": [
    "docs = make_example_cards()\n",
    "bm25 = build_bm25(docs)\n",
    "save_bm25(bm25, docs)\n",
    "print(f\"BM25 index built over {len(docs)} docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6389c9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Vector (k=5) ===\n",
      "[{'type': 'example', 'text': \"Q: average bed height for Jig-1 in last 10 hours\\nSQL: SELECT AVG(t.value) AS avg_bed_height_mm FROM telemetry t JOIN sensors s ON t.sensor_id=s.sensor_id JOIN machines m ON s.machine_id=m.machine_id WHERE s.name='bed_height_mm' AND m.name='Jig-1' AND t.ts >= CURRENT_TIMESTAMP - INTERVAL '10 hours';\"}, {'type': 'example', 'text': \"Q: difference between maximum and minimum bed height for Jig-2 in the last day\\nSQL: SELECT MAX(t.value) - MIN(t.value) AS bed_height_range_mm FROM telemetry t JOIN sensors s ON t.sensor_id = s.sensor_id JOIN machines m ON s.machine_id = m.machine_id WHERE s.name = 'bed_height_mm' AND m.name = 'Jig-2' AND t.ts >= CURRENT_TIMESTAMP - INTERVAL '24 hours';\"}, {'type': 'example', 'text': \"Q: average water flow for Jig-2 in the last 3 days\\nSQL: SELECT AVG(t.value) AS avg_water_m3h FROM telemetry t JOIN sensors s ON t.sensor_id = s.sensor_id JOIN machines m ON s.machine_id = m.machine_id WHERE s.name = 'water_flow_m3h' AND m.name = 'Jig-2' AND t.ts >= CURRENT_TIMESTAMP - INTERVAL '3 days';\"}, {'type': 'example', 'text': \"Q: maximum bed height for each machine today\\nSQL: SELECT m.name, MAX(t.value) AS max_bed_height_mm FROM telemetry t JOIN sensors s ON t.sensor_id = s.sensor_id JOIN machines m ON s.machine_id = m.machine_id WHERE s.name = 'bed_height_mm' AND t.ts::date = CURRENT_DATE GROUP BY m.name ORDER BY m.name;\"}, {'type': 'example', 'text': \"Q: average pulsation frequency for Jig-1 compared to Jig-2 over the last week\\nSQL: SELECT   AVG(CASE WHEN m.name = 'Jig-1' THEN t.value END) AS avg_pulsation_jig1,   AVG(CASE WHEN m.name = 'Jig-2' THEN t.value END) AS avg_pulsation_jig2 FROM telemetry t JOIN sensors s ON t.sensor_id=s.sensor_id JOIN machines m ON s.machine_id=m.machine_id WHERE s.name='pulsation_freq_hz' AND m.name IN ('Jig-1', 'Jig-2') AND t.ts >= CURRENT_TIMESTAMP - INTERVAL '7 days';\"}]\n",
      "- avg_bed_height_10h: HIT\n",
      "   #1: Q: average bed height for Jig-1 in last 10 hours\n",
      "   #2: Q: difference between maximum and minimum bed height for Jig-2 in the last day\n",
      "   #3: Q: average water flow for Jig-2 in the last 3 days\n",
      "[{'type': 'example', 'text': \"Q: tailings chrome by machine in last 24 hours\\nSQL: SELECT m.name, AVG(l.tailings_cr2o3_pct) AS avg_cr FROM lab_samples l JOIN machines m ON l.machine_id=m.machine_id WHERE l.ts >= CURRENT_TIMESTAMP - INTERVAL '24 hours' GROUP BY m.name ORDER BY m.name;\"}, {'type': 'example', 'text': \"Q: average chrome content in tailings per area during the last week\\nSQL: SELECT m.area, AVG(l.tailings_cr2o3_pct) AS avg_cr FROM lab_samples l JOIN machines m ON l.machine_id = m.machine_id WHERE l.ts >= CURRENT_TIMESTAMP - INTERVAL '7 days' GROUP BY m.area ORDER BY m.area;\"}, {'type': 'example', 'text': \"Q: hourly average tailings chrome for each machine today\\nSQL: SELECT m.name, date_trunc('hour', l.ts) AS hour, AVG(l.tailings_cr2o3_pct) AS avg_cr FROM lab_samples l JOIN machines m ON l.machine_id = m.machine_id WHERE l.ts::date = CURRENT_DATE GROUP BY m.name, hour ORDER BY m.name, hour;\"}, {'type': 'example', 'text': \"Q: correlation between clayness index and tailings chrome for Jig-1 in the last 12 hours\\nSQL: SELECT corr(t.value, l.tailings_cr2o3_pct) AS corr_value FROM telemetry t JOIN sensors s ON t.sensor_id = s.sensor_id JOIN machines m ON s.machine_id = m.machine_id JOIN lab_samples l ON l.machine_id = m.machine_id WHERE s.name = 'clayness_index' AND m.name = 'Jig-1' AND t.ts >= CURRENT_TIMESTAMP - INTERVAL '12 hours' AND l.ts >= CURRENT_TIMESTAMP - INTERVAL '12 hours';\"}, {'type': 'example', 'text': \"Q: average water flow when tailings chrome was above 0.5 percent on Jig-4\\nSQL: SELECT AVG(t.value) AS avg_water_flow FROM telemetry t JOIN sensors s ON t.sensor_id=s.sensor_id JOIN machines m ON s.machine_id=m.machine_id WHERE s.name='water_flow_m3h' AND m.name='Jig-4' AND EXISTS (   SELECT 1 FROM lab_samples l   WHERE l.machine_id = m.machine_id   AND l.tailings_cr2o3_pct > 0.5   AND t.ts::date = l.ts::date );\"}]\n",
      "- chrome_by_machine_24h: HIT\n",
      "   #1: Q: tailings chrome by machine in last 24 hours\n",
      "   #2: Q: average chrome content in tailings per area during the last week\n",
      "   #3: Q: hourly average tailings chrome for each machine today\n",
      "[{'type': 'example', 'text': \"Q: hourly make-up water flow for Jig-2 yesterday\\nSQL: SELECT date_trunc('hour', t.ts) AS h, AVG(t.value) AS water_m3h FROM telemetry t JOIN sensors s ON t.sensor_id=s.sensor_id JOIN machines m ON s.machine_id=m.machine_id WHERE s.name='water_flow_m3h' AND m.name='Jig-2' AND t.ts::date = (CURRENT_DATE - INTERVAL '1 day')::date GROUP BY 1 ORDER BY 1;\"}, {'type': 'example', 'text': \"Q: average water flow for Jig-2 in the last 3 days\\nSQL: SELECT AVG(t.value) AS avg_water_m3h FROM telemetry t JOIN sensors s ON t.sensor_id = s.sensor_id JOIN machines m ON s.machine_id = m.machine_id WHERE s.name = 'water_flow_m3h' AND m.name = 'Jig-2' AND t.ts >= CURRENT_TIMESTAMP - INTERVAL '3 days';\"}, {'type': 'example', 'text': \"Q: average water flow when tailings chrome was above 0.5 percent on Jig-4\\nSQL: SELECT AVG(t.value) AS avg_water_flow FROM telemetry t JOIN sensors s ON t.sensor_id=s.sensor_id JOIN machines m ON s.machine_id=m.machine_id WHERE s.name='water_flow_m3h' AND m.name='Jig-4' AND EXISTS (   SELECT 1 FROM lab_samples l   WHERE l.machine_id = m.machine_id   AND l.tailings_cr2o3_pct > 0.5   AND t.ts::date = l.ts::date );\"}, {'type': 'example', 'text': \"Q: hourly average of water flow and clayness for Jig-1 over the last 8 hours\\nSQL: SELECT date_trunc('hour', t.ts) AS hour, AVG(CASE WHEN s.name = 'water_flow_m3h' THEN t.value END) AS avg_water_flow, AVG(CASE WHEN s.name = 'clayness_index' THEN t.value END) AS avg_clayness FROM telemetry t JOIN sensors s ON t.sensor_id = s.sensor_id JOIN machines m ON s.machine_id = m.machine_id WHERE m.name = 'Jig-1' AND s.name IN ('water_flow_m3h','clayness_index') AND t.ts >= CURRENT_TIMESTAMP - INTERVAL '8 hours' GROUP BY hour ORDER BY hour;\"}, {'type': 'example', 'text': \"Q: correlation between clayness index and tailings chrome for Jig-1 in the last 12 hours\\nSQL: SELECT corr(t.value, l.tailings_cr2o3_pct) AS corr_value FROM telemetry t JOIN sensors s ON t.sensor_id = s.sensor_id JOIN machines m ON s.machine_id = m.machine_id JOIN lab_samples l ON l.machine_id = m.machine_id WHERE s.name = 'clayness_index' AND m.name = 'Jig-1' AND t.ts >= CURRENT_TIMESTAMP - INTERVAL '12 hours' AND l.ts >= CURRENT_TIMESTAMP - INTERVAL '12 hours';\"}]\n",
      "- hourly_water_flow_jig2_yday: HIT\n",
      "   #1: Q: hourly make-up water flow for Jig-2 yesterday\n",
      "   #2: Q: average water flow for Jig-2 in the last 3 days\n",
      "   #3: Q: average water flow when tailings chrome was above 0.5 percent on Jig-4\n",
      "Hit@5: 3/3 = 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"\\ntry:\\n    run_suite(\"BM25\", retrieve_bm25, QUERIES, k=K)\\nexcept FileNotFoundError:\\n    print(\"BM25 store not found. Build it with: python -m src.retrieval.build_bm25\")\\nrun_suite(\"Hybrid\", retrieve_hybrid, QUERIES, k=K)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ----- RETRIEVERS -----\n",
    "_embedder = SentenceTransformer(EMB)\n",
    "_qdrant = QdrantClient(QDRANT_URL)\n",
    "K = 5\n",
    "\n",
    "def retrieve_vector(q: str, k: int = K) -> List[Dict]:\n",
    "    v = _embedder.encode([q], normalize_embeddings=True)[0]\n",
    "    hits = _qdrant.search(collection_name=COLL, query_vector=v.tolist(), limit=k)\n",
    "    return [h.payload for h in hits]\n",
    "\n",
    "def retrieve_bm25(q: str, k: int = K) -> List[Dict]:\n",
    "    bm25, docs = load_bm25()\n",
    "    import numpy as np\n",
    "    scores = bm25.get_scores(q.lower().split())\n",
    "    idx = np.argsort(scores)[::-1][:k]\n",
    "    return [docs[i] for i in idx]\n",
    "\n",
    "def retrieve_hybrid(q: str, k: int = K, alpha: float = 0.7) -> List[Dict]:\n",
    "    # fuse vector + bm25 (min-max normalize bm25)\n",
    "    bm25, bm_docs = load_bm25()\n",
    "    kv = 3 * k\n",
    "    v = _embedder.encode([q], normalize_embeddings=True)[0]\n",
    "    v_hits = _qdrant.search(collection_name=COLL, query_vector=v.tolist(), limit=kv)\n",
    "    v_scores = {h.payload[\"text\"]: float(h.score) for h in v_hits}\n",
    "\n",
    "    scores_bm = bm25.get_scores(q.lower().split())\n",
    "    order_bm = np.argsort(scores_bm)[::-1][:kv]\n",
    "    bm_top = [bm_docs[i] for i in order_bm]\n",
    "    s_bm = scores_bm[order_bm]\n",
    "    if s_bm.max() > s_bm.min():\n",
    "        s_bm = (s_bm - s_bm.min()) / (s_bm.max() - s_bm.min())\n",
    "    else:\n",
    "        s_bm = np.zeros_like(s_bm)\n",
    "\n",
    "    fused = {}\n",
    "    for d, s in zip(bm_top, s_bm):\n",
    "        fused[d[\"text\"]] = fused.get(d[\"text\"], 0.0) + (1 - alpha) * float(s)\n",
    "    for txt, s in v_scores.items():\n",
    "        fused[txt] = fused.get(txt, 0.0) + alpha * s\n",
    "\n",
    "    top = sorted(fused.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "    # map text -> doc\n",
    "    text2doc = {d[\"text\"]: d for d in bm_docs}\n",
    "    return [text2doc[t] for t, _ in top if t in text2doc]\n",
    "\n",
    "# ----- EVAL -----\n",
    "def normalize(s: str) -> str:\n",
    "    return \" \".join(s.strip().lower().split())\n",
    "\n",
    "def is_target_example(doc: Dict, expected_q_prefix: str) -> bool:\n",
    "    \"\"\"\n",
    "    Your example docs have payload like:\n",
    "      {\"type\":\"example\",\"text\":\"Q: ...\\nSQL: ...\"}\n",
    "    We check that 'text' starts with the question line.\n",
    "    \"\"\"\n",
    "    if not doc or doc.get(\"type\") != \"example\":\n",
    "        return False\n",
    "    txt = doc.get(\"text\", \"\")\n",
    "    # Compare only the 'Q: ...' line prefix ignoring spaces/case\n",
    "    first_line = txt.splitlines()[0]\n",
    "    return normalize(first_line).startswith(normalize(expected_q_prefix))\n",
    "\n",
    "def run_suite(name: str, retriever, queries: Dict[str, str], k: int = K):\n",
    "    print(f\"\\n=== {name} (k={k}) ===\")\n",
    "    hits = 0\n",
    "    for label, qline in queries.items():\n",
    "        results = retriever(qline, k=k)\n",
    "        print(results)\n",
    "        ok = any(is_target_example(doc, qline) for doc in results)\n",
    "        hits += int(ok)\n",
    "        print(f\"- {label}: {'HIT' if ok else 'MISS'}\")\n",
    "        # show top-3 titles for transparency\n",
    "        for i, d in enumerate(results[:3], 1):\n",
    "            t0 = d.get(\"text\",\"\").splitlines()[0]\n",
    "            print(f\"   #{i}: {t0[:90]}\")\n",
    "    print(f\"Hit@{k}: {hits}/{len(queries)} = {hits/len(queries):.2f}\")\n",
    "\n",
    "# The three queries you want to test (exact 'Q:' lines)\n",
    "QUERIES = {\n",
    "    \"avg_bed_height_10h\":\n",
    "        \"Q: average bed height for Jig-1 in last 10 hours\",\n",
    "    \"chrome_by_machine_24h\":\n",
    "        \"Q: tailings chrome by machine in last 24 hours\",\n",
    "    \"hourly_water_flow_jig2_yday\":\n",
    "        \"Q: hourly make-up water flow for Jig-2 yesterday\",\n",
    "}\n",
    "\n",
    "# Run all methods you have available\n",
    "run_suite(\"Vector\", retrieve_vector, QUERIES, k=K)\n",
    "\"\"\"\"\n",
    "try:\n",
    "    run_suite(\"BM25\", retrieve_bm25, QUERIES, k=K)\n",
    "except FileNotFoundError:\n",
    "    print(\"BM25 store not found. Build it with: python -m src.retrieval.build_bm25\")\n",
    "run_suite(\"Hybrid\", retrieve_hybrid, QUERIES, k=K)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61058612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
